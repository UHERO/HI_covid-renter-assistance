sim_dist<-bind_rows(sim_dist, new_row)
}
sim_cdf<-sim_dist %>%
mutate(pr_x = count/max(sim_dist$count))
total_sim_cdf<-bind_rows(total_sim_cdf, sim_cdf)
rm(final_sim, final_renters)
}
}
# Loop over each scenario, 1 - 4, repeat 100 times
for (scenario in scenarios){
# foreach(scenario = scenarios) %dopar% {
# Assign Unemployment assistance for the current scenario
add_UI<-if_else(scenario == 1, 0, if_else(scenario == 2, 400, if_else(scenario == 3, 800, if(scenario == 4) 1200)))
# for (i in 1:n_iterations){
foreach(i = 1:n_iterations) %dopar% {
progress(i)
### Low income:
# Generate the sampled/unsampled individuals and randomly assign job losses
sampled_low<-simulation_dataset %>%
filter(income_cat == "low") %>%
group_by(UHERO_mnemonic) %>%
nest() %>%
filter(!is.na(UHERO_mnemonic)) %>%
ungroup() %>%
left_join(select(n_jobs, UHERO_mnemonic, n_low), by = "UHERO_mnemonic") %>%
mutate(samp = map2(data, n_low, sample_n)) %>%
select(-data) %>%
unnest(samp) %>%
mutate(inc_wage_new = pmin(inc_wage*0.60, 648*52) + add_UI*12,
inc_total_new = (inc_total - inc_wage) + inc_wage_new,
affected = 1) %>%
select(-n_low)
unsampled_low<-simulation_dataset %>%
filter(income_cat == "low") %>%
filter(!(unique_id %in% sampled_low$unique_id)) %>%
mutate(inc_wage_new = inc_total,
inc_total_new = inc_total,
affected = 0)
### High Income
# Generate the sampled/unsampled individuals and randomly assign job losses
sampled_high<-simulation_dataset %>%
filter(income_cat == "high") %>%
group_by(UHERO_mnemonic) %>%
nest() %>%
filter(!is.na(UHERO_mnemonic)) %>%
ungroup() %>%
left_join(select(n_jobs, UHERO_mnemonic, n_high), by = "UHERO_mnemonic") %>%
mutate(samp = map2(data, n_high, sample_n)) %>%
select(-data) %>%
unnest(samp) %>%
mutate(inc_wage_new = pmin(inc_wage*0.60, 648*52) + add_UI*12,
inc_total_new = (inc_total - inc_wage) + inc_wage_new,
affected = 1) %>%
select(-n_high)
unsampled_high<-simulation_dataset %>%
filter(income_cat == "high") %>%
filter(!(unique_id %in% sampled_high$unique_id)) %>%
mutate(inc_wage_new = inc_wage,
inc_total_new = inc_total,
affected = 0)
# Create the unsampled group, i.e., income category = "unassigned"
unsampled_na<-simulation_dataset %>%
filter(income_cat == "unassigned") %>%
mutate(inc_wage_new = inc_wage,
inc_total_new = inc_total,
affected = 0)
# Bind rows of sampled/unsampled to perform necessary aggregations/calculations
final_sim<-bind_rows(sampled_low, unsampled_low, sampled_high, unsampled_high, unsampled_na)
# Filter the simulation data to include only renter households, summarize primary variables, and calculate household level outcome variables
final_renters<-final_sim %>%
filter(OWNERSHP == 2) %>%
group_by(hhid) %>%
summarize(hh_income = mean(hh_income),
rent_grs = mean(rent_grs),
rent_burden = mean(rent_burden, na.rm = T),
hh_affected = max(affected),
hh_income_new = if_else(hh_affected == 1, sum(inc_total_new, na.rm = T), hh_income)) %>%
mutate(rent_burden_new = if_else(rent_grs == 0, 0, pmin(rent_grs/(hh_income_new/12)*100, 200)),
burden_change = rent_burden_new - rent_burden,
support_needed = if_else(hh_affected == 1, pmax(0, round(rent_grs - ((rent_burden/100)*(hh_income_new/12)),5)), 0))
# Calculate the additional support needed to return affected renters to their prior level of rent burden
affected_rental_support_row<-c("scenario" = scenario, "iteration" = i,
"AvgHHSupport" = mean(filter(final_renters, hh_affected == 1)$support_needed),
"TotalHHSupport" = sum(filter(final_renters, hh_affected == 1)$support_needed))
total_affected_rental_support<-bind_rows(total_affected_rental_support, affected_rental_support_row)
# Calculate the change in rental burden for each household
max_change<-round(max(final_renters$burden_change))+1
burden_change<-tibble()
for (k in 1:max_change){
new_change_row<-c("scenario" = scenario, "iteration" = i, "burden_change" = k,
"cdf_count" = nrow(filter(final_renters, burden_change <= k)))
burden_change<-bind_rows(burden_change, new_change_row)
}
total_burden_change<-bind_rows(total_burden_change, burden_change)
# Calculate the distribution of rental burden
sim_dist<-tibble()
for (j in 1:200){
new_row<-c("scenario" = scenario, "iteration" = i, "burden" = j, "count" = nrow(filter(final_renters, rent_burden_new <= j)))
sim_dist<-bind_rows(sim_dist, new_row)
}
sim_cdf<-sim_dist %>%
mutate(pr_x = count/max(sim_dist$count))
total_sim_cdf<-bind_rows(total_sim_cdf, sim_cdf)
rm(final_sim, final_renters)
}
}
n_iterations
# Loop over each scenario, 1 - 4, repeat 100 times
# for (scenario in scenarios){
foreach(scenario = scenarios, .packages = "tidyverse") %dopar% {
# Assign Unemployment assistance for the current scenario
add_UI<-if_else(scenario == 1, 0, if_else(scenario == 2, 400, if_else(scenario == 3, 800, if(scenario == 4) 1200)))
# for (i in 1:n_iterations){
foreach(i = 1:n_iterations, .packages = "tidyverse") %dopar% {
### Low income:
# Generate the sampled/unsampled individuals and randomly assign job losses
sampled_low<-simulation_dataset %>%
filter(income_cat == "low") %>%
group_by(UHERO_mnemonic) %>%
nest() %>%
filter(!is.na(UHERO_mnemonic)) %>%
ungroup() %>%
left_join(select(n_jobs, UHERO_mnemonic, n_low), by = "UHERO_mnemonic") %>%
mutate(samp = map2(data, n_low, sample_n)) %>%
select(-data) %>%
unnest(samp) %>%
mutate(inc_wage_new = pmin(inc_wage*0.60, 648*52) + add_UI*12,
inc_total_new = (inc_total - inc_wage) + inc_wage_new,
affected = 1) %>%
select(-n_low)
unsampled_low<-simulation_dataset %>%
filter(income_cat == "low") %>%
filter(!(unique_id %in% sampled_low$unique_id)) %>%
mutate(inc_wage_new = inc_total,
inc_total_new = inc_total,
affected = 0)
### High Income
# Generate the sampled/unsampled individuals and randomly assign job losses
sampled_high<-simulation_dataset %>%
filter(income_cat == "high") %>%
group_by(UHERO_mnemonic) %>%
nest() %>%
filter(!is.na(UHERO_mnemonic)) %>%
ungroup() %>%
left_join(select(n_jobs, UHERO_mnemonic, n_high), by = "UHERO_mnemonic") %>%
mutate(samp = map2(data, n_high, sample_n)) %>%
select(-data) %>%
unnest(samp) %>%
mutate(inc_wage_new = pmin(inc_wage*0.60, 648*52) + add_UI*12,
inc_total_new = (inc_total - inc_wage) + inc_wage_new,
affected = 1) %>%
select(-n_high)
unsampled_high<-simulation_dataset %>%
filter(income_cat == "high") %>%
filter(!(unique_id %in% sampled_high$unique_id)) %>%
mutate(inc_wage_new = inc_wage,
inc_total_new = inc_total,
affected = 0)
# Create the unsampled group, i.e., income category = "unassigned"
unsampled_na<-simulation_dataset %>%
filter(income_cat == "unassigned") %>%
mutate(inc_wage_new = inc_wage,
inc_total_new = inc_total,
affected = 0)
# Bind rows of sampled/unsampled to perform necessary aggregations/calculations
final_sim<-bind_rows(sampled_low, unsampled_low, sampled_high, unsampled_high, unsampled_na)
# Filter the simulation data to include only renter households, summarize primary variables, and calculate household level outcome variables
final_renters<-final_sim %>%
filter(OWNERSHP == 2) %>%
group_by(hhid) %>%
summarize(hh_income = mean(hh_income),
rent_grs = mean(rent_grs),
rent_burden = mean(rent_burden, na.rm = T),
hh_affected = max(affected),
hh_income_new = if_else(hh_affected == 1, sum(inc_total_new, na.rm = T), hh_income)) %>%
mutate(rent_burden_new = if_else(rent_grs == 0, 0, pmin(rent_grs/(hh_income_new/12)*100, 200)),
burden_change = rent_burden_new - rent_burden,
support_needed = if_else(hh_affected == 1, pmax(0, round(rent_grs - ((rent_burden/100)*(hh_income_new/12)),5)), 0))
# Calculate the additional support needed to return affected renters to their prior level of rent burden
affected_rental_support_row<-c("scenario" = scenario, "iteration" = i,
"AvgHHSupport" = mean(filter(final_renters, hh_affected == 1)$support_needed),
"TotalHHSupport" = sum(filter(final_renters, hh_affected == 1)$support_needed))
total_affected_rental_support<-bind_rows(total_affected_rental_support, affected_rental_support_row)
# Calculate the change in rental burden for each household
max_change<-round(max(final_renters$burden_change))+1
burden_change<-tibble()
for (k in 1:max_change){
new_change_row<-c("scenario" = scenario, "iteration" = i, "burden_change" = k,
"cdf_count" = nrow(filter(final_renters, burden_change <= k)))
burden_change<-bind_rows(burden_change, new_change_row)
}
total_burden_change<-bind_rows(total_burden_change, burden_change)
# Calculate the distribution of rental burden
sim_dist<-tibble()
for (j in 1:200){
new_row<-c("scenario" = scenario, "iteration" = i, "burden" = j, "count" = nrow(filter(final_renters, rent_burden_new <= j)))
sim_dist<-bind_rows(sim_dist, new_row)
}
sim_cdf<-sim_dist %>%
mutate(pr_x = count/max(sim_dist$count))
total_sim_cdf<-bind_rows(total_sim_cdf, sim_cdf)
rm(final_sim, final_renters)
}
}
total_burden_change
scenario
scenarios
scenarios<-1:4
# Create empty dataframes for various simulation results
total_sim_cdf<-tibble()
total_burden_change<-tibble()
loss_assignment<-tibble()
total_affected_rental_support<-tibble()
# Loop over each scenario, 1 - 4, repeat 100 times
# for (scenario in scenarios){
foreach(scenario = scenarios, .packages = "tidyverse") %dopar% {
# Assign Unemployment assistance for the current scenario
add_UI<-if_else(scenario == 1, 0, if_else(scenario == 2, 400, if_else(scenario == 3, 800, if(scenario == 4) 1200)))
# for (i in 1:n_iterations){
foreach(i = 1:n_iterations, .packages = "tidyverse") %dopar% {
### Low income:
# Generate the sampled/unsampled individuals and randomly assign job losses
sampled_low<-simulation_dataset %>%
filter(income_cat == "low") %>%
group_by(UHERO_mnemonic) %>%
nest() %>%
filter(!is.na(UHERO_mnemonic)) %>%
ungroup() %>%
left_join(select(n_jobs, UHERO_mnemonic, n_low), by = "UHERO_mnemonic") %>%
mutate(samp = map2(data, n_low, sample_n)) %>%
select(-data) %>%
unnest(samp) %>%
mutate(inc_wage_new = pmin(inc_wage*0.60, 648*52) + add_UI*12,
inc_total_new = (inc_total - inc_wage) + inc_wage_new,
affected = 1) %>%
select(-n_low)
unsampled_low<-simulation_dataset %>%
filter(income_cat == "low") %>%
filter(!(unique_id %in% sampled_low$unique_id)) %>%
mutate(inc_wage_new = inc_total,
inc_total_new = inc_total,
affected = 0)
### High Income
# Generate the sampled/unsampled individuals and randomly assign job losses
sampled_high<-simulation_dataset %>%
filter(income_cat == "high") %>%
group_by(UHERO_mnemonic) %>%
nest() %>%
filter(!is.na(UHERO_mnemonic)) %>%
ungroup() %>%
left_join(select(n_jobs, UHERO_mnemonic, n_high), by = "UHERO_mnemonic") %>%
mutate(samp = map2(data, n_high, sample_n)) %>%
select(-data) %>%
unnest(samp) %>%
mutate(inc_wage_new = pmin(inc_wage*0.60, 648*52) + add_UI*12,
inc_total_new = (inc_total - inc_wage) + inc_wage_new,
affected = 1) %>%
select(-n_high)
unsampled_high<-simulation_dataset %>%
filter(income_cat == "high") %>%
filter(!(unique_id %in% sampled_high$unique_id)) %>%
mutate(inc_wage_new = inc_wage,
inc_total_new = inc_total,
affected = 0)
# Create the unsampled group, i.e., income category = "unassigned"
unsampled_na<-simulation_dataset %>%
filter(income_cat == "unassigned") %>%
mutate(inc_wage_new = inc_wage,
inc_total_new = inc_total,
affected = 0)
# Bind rows of sampled/unsampled to perform necessary aggregations/calculations
final_sim<-bind_rows(sampled_low, unsampled_low, sampled_high, unsampled_high, unsampled_na)
# Filter the simulation data to include only renter households, summarize primary variables, and calculate household level outcome variables
final_renters<-final_sim %>%
filter(OWNERSHP == 2) %>%
group_by(hhid) %>%
summarize(hh_income = mean(hh_income),
rent_grs = mean(rent_grs),
rent_burden = mean(rent_burden, na.rm = T),
hh_affected = max(affected),
hh_income_new = if_else(hh_affected == 1, sum(inc_total_new, na.rm = T), hh_income)) %>%
mutate(rent_burden_new = if_else(rent_grs == 0, 0, pmin(rent_grs/(hh_income_new/12)*100, 200)),
burden_change = rent_burden_new - rent_burden,
support_needed = if_else(hh_affected == 1, pmax(0, round(rent_grs - ((rent_burden/100)*(hh_income_new/12)),5)), 0))
# Calculate the additional support needed to return affected renters to their prior level of rent burden
affected_rental_support_row<-c("scenario" = scenario, "iteration" = i,
"AvgHHSupport" = mean(filter(final_renters, hh_affected == 1)$support_needed),
"TotalHHSupport" = sum(filter(final_renters, hh_affected == 1)$support_needed))
total_affected_rental_support<-bind_rows(total_affected_rental_support, affected_rental_support_row)
# Calculate the change in rental burden for each household
max_change<-round(max(final_renters$burden_change))+1
burden_change<-tibble()
for (k in 1:max_change){
new_change_row<-c("scenario" = scenario, "iteration" = i, "burden_change" = k,
"cdf_count" = nrow(filter(final_renters, burden_change <= k)))
burden_change<-bind_rows(burden_change, new_change_row)
}
total_burden_change<-bind_rows(total_burden_change, burden_change)
# Calculate the distribution of rental burden
sim_dist<-tibble()
for (j in 1:200){
new_row<-c("scenario" = scenario, "iteration" = i, "burden" = j, "count" = nrow(filter(final_renters, rent_burden_new <= j)))
sim_dist<-bind_rows(sim_dist, new_row)
}
sim_cdf<-sim_dist %>%
mutate(pr_x = count/max(sim_dist$count))
total_sim_cdf<-bind_rows(total_sim_cdf, sim_cdf)
rm(final_sim, final_renters)
}
}
total_sim_cdf
View(total_sim_cdf)
View(total_affected_rental_support)
foreach(i=1:10) %do% rnorm()
foreach(i=1:10) %do% rnorm(1)
foreach(i=1:10) %do% rnorm(4)
foreach(i=1:2) %do% rnorm(4)
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE)
library(rmarkdown)
library(tidyverse)
library(lubridate)
library(scales)
library(svMisc)
library(gt)
options(scipen = 999)
n_iterations <- 100
n_iterations <- 1
uhero_forecast<-read_csv("data/uhero_jobs_forecast.csv")
### Clean up job columns:
# List of UHERO job mnemonics to retain in the forecast file
job_mnemonics<-c("E", "E_NF", "EGV", "EGVFD", "E_GVSL", "ECT", "EMN", "E_TRADE", "E_TU",
"E_FIR", "E_SV", "EHC", "EAF", "E_ELSE")
uhero_jobs<-uhero_forecast %>%
select(Date, starts_with(job_mnemonics)) %>%
select(Date, ends_with("(new)"))
# Rename columns
new_colnames<-str_remove_all(string = colnames(uhero_jobs), pattern = "@HI \\(new\\)*")
colnames(uhero_jobs)<-new_colnames
# Create the agricultural job series
uhero_jobs<-uhero_jobs %>%
mutate(EAG = E - E_NF)
### Calculate year over year job losses by industry
uhero_job_losses<-uhero_jobs %>%
mutate_at(.vars = vars(-Date), function(x) (x - lag(x, n = 4))*1000) %>%
mutate_at(.vars = vars(-Date), function(x) if_else(x < 0, abs(x), 0))
# Read IPUMS csv file
ipums_raw<-read_csv("data/ACS_2017-2018.csv")
### Filter the IPUMS data
# Restrict the sample to include 2018 survey results
# Remove OWNERSHP = 0, these are neither renter or homeowner households and thus will not be assigned job losses
# Per the IPUMS Coding Manual, recode NA entries as NA
ipums_2018<-filter(ipums_raw, YEAR == 2018 & OWNERSHP != 0) %>%
mutate(inc_total = INCTOT %>% na_if(9999999),
inc_wage = INCWAGE %>% na_if(999999) %>% na_if(999998),
hh_income = HHINCOME %>% na_if(9999999),
rent_grs = if_else(OWNERSHP == 2, RENTGRS, NA_real_),
rent_burden = if_else(rent_grs == 0, 0, pmin(rent_grs/(hh_income/12)*100, 200)))
### Apply household weightings to the data
# Duplicate households based on household weight (HHWT)
# Create a new unique HH identifier for the duplicated households
ipums_weighted<-ipums_2018 %>%
group_by(SERIAL) %>%
uncount(weights = HHWT, .id = "ID") %>%
unite("hhid", c("SERIAL", "ID"), sep = "_", remove = F) %>%
ungroup() %>%
group_by(hhid)
# Load the industry uhero mnemonic csv file
ind_uhero_match<-read_csv("data/industry_code_uhero_mnemonics.csv")
# Assign the uhero mnemonic to the ipums industry code
ipums_uhero<-left_join(ipums_weighted, ind_uhero_match, by = c("IND" = "2017 Census Code")) %>%
rowid_to_column(var = "unique_id") %>%
ungroup()
# Get unique list of industries in the ACS data
jobs<-unique(na.omit(ipums_uhero$UHERO_mnemonic))
# Choose which as of date you want for annual job losses
as_of_date<-"2020-07-01"
uhero_job_loss_reshape<-uhero_job_losses %>%
pivot_longer(-Date, names_to = "UHERO_mnemonic", values_to = "job_losses") %>%
filter(Date == as_of_date & UHERO_mnemonic %in% jobs) %>%
select(-Date)
# Revise the number of job losses to equal the minimum of the total jobs or total job losses
n_jobs<-ipums_uhero %>%
group_by(UHERO_mnemonic) %>%
tally() %>%
na.omit() %>%
left_join(uhero_job_loss_reshape, by = "UHERO_mnemonic") %>%
mutate(revised_losses = pmin(n, job_losses)) %>%
select(-n, -job_losses) %>%
mutate(n_low = round(revised_losses*0.65),
n_high = round(revised_losses*0.35))
# Calculate the median individual income for each industry
median_income<-ipums_uhero %>%
group_by(UHERO_mnemonic) %>%
summarize(median_income = median(inc_total, na.rm = T)) %>%
na.omit()
# Add a median income column to the individual level data to determine whether each individual falls into the low/high income category
# Exclude all individuals wtih wage income equal to zero so that they cannot randomly be assigned a job loss
simulation_dataset<-left_join(ipums_uhero, median_income, by = "UHERO_mnemonic") %>%
mutate(income_cat = case_when(inc_total < median_income & inc_wage != 0 ~ "low",
inc_total >= median_income & inc_wage != 0 ~ "high",
is.na(UHERO_mnemonic) | inc_wage == 0 ~ "unassigned"))
# Create a table summarizing the UHERO forecasted job categories, number of wage earners per category, and number of forecasted job losses
job_summary_tbl<-simulation_dataset %>%
left_join(select(n_jobs, revised_losses, UHERO_mnemonic), by = "UHERO_mnemonic") %>%
select(unique_id, hhid, inc_wage, hh_income, revised_losses, Industry_Sector, UHERO_mnemonic) %>%
filter(!is.na(Industry_Sector)) %>%
group_by(UHERO_mnemonic) %>%
filter(inc_wage > 0) %>%
summarize("Sectors Included" = list(unique(Industry_Sector)),
"Number of Wage Earners" = n(),
"Annual Job Losses (as of 2020 Q3)" = mean(revised_losses)) %>%
gt() %>%
fmt_number(columns = vars("Number of Wage Earners", "Annual Job Losses (as of 2020 Q3)"), decimal = 0)
gtsave(job_summary_tbl)
gtsave(job_summary_tbl, filename = "job_summary_tbl.png")
# Create a table summarizing the UHERO forecasted job categories, number of wage earners per category, and number of forecasted job losses
job_summary_tbl<-simulation_dataset %>%
left_join(select(n_jobs, revised_losses, UHERO_mnemonic), by = "UHERO_mnemonic") %>%
select(unique_id, hhid, inc_wage, hh_income, revised_losses, Industry_Sector, UHERO_mnemonic) %>%
filter(!is.na(Industry_Sector)) %>%
group_by(UHERO_mnemonic) %>%
filter(inc_wage > 0) %>%
summarize("Sectors Included" = list(unique(Industry_Sector)),
"Number of Wage Earners" = n(),
"Annual Job Losses (as of 2020 Q3)" = mean(revised_losses)) %>%
gt() %>%
fmt_number(columns = vars("Number of Wage Earners", "Annual Job Losses (as of 2020 Q3)"), decimal = 0)
job_summary_tbl
gtsave(job_summary_tbl, filename = "job_summary_tbl.png")
getwd()
gtsave(job_summary_tbl, filename = "job_summary_tbl")
gtsave(job_summary_tbl, filename = "job_summary_tbl.png")
webshot::install_phantomjs()
gtsave(job_summary_tbl, filename = "job_summary_tbl.png")
gtsave(job_summary_tbl, filename = "job_summary_tbl.png")
gtsave(job_summary_tbl, filename = "job_summary_tbl.png")
# Load the industry uhero mnemonic csv file
ind_uhero_match<-read_csv("data/industry_code_uhero_mnemonics.csv")
# Assign the uhero mnemonic to the ipums industry code
ipums_uhero<-left_join(ipums_weighted, ind_uhero_match, by = c("IND" = "2017 Census Code")) %>%
rowid_to_column(var = "unique_id") %>%
ungroup()
# Get unique list of industries in the ACS data
jobs<-unique(na.omit(ipums_uhero$UHERO_mnemonic))
# Choose which as of date you want for annual job losses
as_of_date<-"2020-07-01"
uhero_job_loss_reshape<-uhero_job_losses %>%
pivot_longer(-Date, names_to = "UHERO_mnemonic", values_to = "job_losses") %>%
filter(Date == as_of_date & UHERO_mnemonic %in% jobs) %>%
select(-Date)
# Revise the number of job losses to equal the minimum of the total jobs or total job losses
n_jobs<-ipums_uhero %>%
group_by(UHERO_mnemonic) %>%
tally() %>%
na.omit() %>%
left_join(uhero_job_loss_reshape, by = "UHERO_mnemonic") %>%
mutate(revised_losses = pmin(n, job_losses)) %>%
select(-n, -job_losses) %>%
mutate(n_low = round(revised_losses*0.65),
n_high = round(revised_losses*0.35))
# Calculate the median individual income for each industry
median_income<-ipums_uhero %>%
group_by(UHERO_mnemonic) %>%
summarize(median_income = median(inc_total, na.rm = T)) %>%
na.omit()
# Add a median income column to the individual level data to determine whether each individual falls into the low/high income category
# Exclude all individuals wtih wage income equal to zero so that they cannot randomly be assigned a job loss
simulation_dataset<-left_join(ipums_uhero, median_income, by = "UHERO_mnemonic") %>%
mutate(income_cat = case_when(inc_total < median_income & inc_wage != 0 ~ "low",
inc_total >= median_income & inc_wage != 0 ~ "high",
is.na(UHERO_mnemonic) | inc_wage == 0 ~ "unassigned"))
# Create a table summarizing the UHERO forecasted job categories, number of wage earners per category, and number of forecasted job losses
job_summary_tbl<-simulation_dataset %>%
left_join(select(n_jobs, revised_losses, UHERO_mnemonic), by = "UHERO_mnemonic") %>%
select(unique_id, hhid, inc_wage, hh_income, revised_losses, Industry_Sector, UHERO_mnemonic) %>%
filter(!is.na(Industry_Sector)) %>%
group_by(UHERO_mnemonic) %>%
filter(inc_wage > 0) %>%
summarize("Sectors Included" = list(unique(Industry_Sector)),
"Number of Wage Earners" = n(),
"Annual Job Losses (as of 2020 Q3)" = mean(revised_losses)) %>%
gt() %>%
fmt_number(columns = vars("Number of Wage Earners", "Annual Job Losses (as of 2020 Q3)"), decimal = 0)
gtsave(job_summary_tbl, filename = "job_summary_tbl.png")
# Clean up variables tables prior to running simulation
rm(ipums_raw, ipums_2018, ipums_uhero, uhero_forecast, uhero_jobs, uhero_job_losses, uhero_job_loss_reshape)
gc()
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
library(devtools)
devtools::install_github("rstudio/gt")
devtools::install_github("rstudio/gt")
install.packages(c("backports", "boot", "class", "classInt", "dbplyr", "ellipsis", "fs", "gdtools", "ggplot2", "glmnet", "haven", "htmltools", "httpuv", "isoband", "KernSmooth", "later", "lattice", "leafem", "lubridate", "lwgeom", "mapview", "MASS", "modelr", "nlme", "nnet", "pdftools", "pillar", "pkgbuild", "pkgload", "plotly", "promises", "ps", "purrr", "raster", "Rcpp", "RCurl", "reshape2", "rgdal", "rgeos", "rlang", "rmarkdown", "sf", "shinyalert", "sp", "spatial", "stars", "survival", "systemfonts", "tidyr", "tidyselect", "tinytex", "units", "vctrs", "withr", "xfun", "xml2"))
install.packages(c("backports", "boot", "class", "classInt", "dbplyr", "ellipsis", "fs", "gdtools", "ggplot2", "glmnet", "haven", "htmltools", "httpuv", "isoband", "KernSmooth", "later", "lattice", "leafem", "lubridate", "lwgeom", "mapview", "MASS", "modelr", "nlme", "nnet", "pdftools", "pillar", "pkgbuild", "pkgload", "plotly", "promises", "ps", "purrr", "raster", "Rcpp", "RCurl", "reshape2", "rgdal", "rgeos", "rlang", "rmarkdown", "sf", "shinyalert", "sp", "spatial", "stars", "survival", "systemfonts", "tidyr", "tidyselect", "tinytex", "units", "vctrs", "withr", "xfun", "xml2"))
install.packages(c("backports", "boot", "class", "classInt", "dbplyr", "ellipsis", "fs", "gdtools", "ggplot2", "glmnet", "haven", "htmltools", "httpuv", "isoband", "KernSmooth", "later", "lattice", "leafem", "lubridate", "lwgeom", "mapview", "MASS", "modelr", "nlme", "nnet", "pdftools", "pillar", "pkgbuild", "pkgload", "plotly", "promises", "ps", "purrr", "raster", "Rcpp", "RCurl", "reshape2", "rgdal", "rgeos", "rlang", "rmarkdown", "sf", "shinyalert", "sp", "spatial", "stars", "survival", "systemfonts", "tidyr", "tidyselect", "tinytex", "units", "vctrs", "withr", "xfun", "xml2"))
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
version(rlang)
library(tidyr)
install.packages("rlang")
library(tidyverse)
library(rland)
library(rlang)
library(tidyverse)
version
library(installr)
updateR()
